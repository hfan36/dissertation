\chapter{GEOMETRICAL CALIBRATION OF THE CT SYSTEM}
\label{chap:calibration}

\section{Background}
The geometry of the computed tomography system can be described using a set of global parameters.  These parameters are crucial for the reconstruction algorithm in order to provide the best object resolution.  Since it is impossible to know precisely the geometry of the system after assembly, a calibration method is needed in order to calculate these system parameters and to account for misalignment of the system prior to image reconstruction.  

In cone-beam tomography, it is well known that using inaccurate parameters can produce severe artifacts~\citep{Li1994a, Li1994b, Wang1998}. Methods for estimating geometrical parameters of tomographic scanners have been investigated by many groups since 1987, starting with Gullberg~\citep{Gullberg1987}.  Some calibration methods tend to be specific to the 2-dimensional parallel-beam geometry~\citep{Azevedo1990, Busemann1987}; others are only for 2-dimensional fan-beam geometry~\citep{Crawford1988, Hsieh1999, Gullberg1987}.  In these earlier methods, the overall approach to calibration is to estimate the geometric parameters by first measuring the locations of point objects on the detector and determining the analytic expressions for these point-object locations as functions of the unknown scanner parameters and unknown positions of the point objects.  This step provides a set of nonlinear equations, which are then solved using an iterative method such as the Levenberg-Marquard algorithm~\citep{Rougee1993}.  The downside of this method is that the algorithms rely heavily on a highly nonlinear parameter-estimation problem and are highly sensitive to the initial estimations and the sequential order in which the parameters are estimated.  There are questions of stability and uniqueness of the parameters.  It is uncertain if local minima exist or if more than one set of calibration parameters can satisfy these equations.  This work was later extended to 3-dimensional cone-beam scanners~\citep{Gullberg1990}; however, the degree of freedoms were restricted, and some shift parameters were assumed to be known.

To avoid initialization and converging problems created by the Levenberg-Marquard algorithm, many authors have proposed methods that employ direct calculations of the system parameters.  In 1999, Broonikov proposed a method that required only two 180$\degree$-opposed projection images of  a circular aperture.  Later authors such as Noo et al, Yang et al, and Cho et al had similar ideas in which they used a set of intermediate equations to describe the projection-orbit data of fiducial markers~\citep{Noo2000, Yang2006, Cho2005}.  The equations proposed by Noo et al and Yang et al were slightly different from each other.  In Cho et al's case, they used a rapid prototype printer to create a phantom that contains multiple fiducial markers to produce several sets of rings about the rotation axis so that the phantom does not need to be rotated during data acquisition.  However, all of these methods are limited to a restricted set of parameters, usually omitting out-of-plane rotation of the detector.  In 2004, Smekal et al introduced another analytical method to solve for all system parameters with the exception of two distance parameters, which are calculated as the ratio between the two.  The advantage of this method is that it is insensitive to the precise extraction of the phantom point projection location on the detector~\citep{Smekal2004}.  In 2008, Panetta~\citep{Panetta2008} proposed a new method in which they measured the misalignment parameters of a cone-beam scanner by minimizing a geometry-dependent cost function.  This cost function is computed from the projection data of a generic object; hence, no a-priori knowledge of the object shape or position is required.  In 2011, Jared Moore used the MLEM algorithm to estimate all system parameters by calculating the projection of a known phantom at two 90$\degree$-opposed angles.

In the next section, we will describe the calibration method that was used for the prototype x-ray CT system.  We will first define the global coordinate system, then we will describe the steps and methods that were used to find all system calibration parameters.

\section{Defining Geometric Parameters}
We need to first define a global coordinate system in order to describe the scan geometry of the CT system.  The z-axis is defined as the rotation axis of the object and is set by the rotation stage; the y-axis is defined as a perpendicular line to the z-axis.  It passes through the x-ray source and through the ideal x-ray screen and camera sensor.  The y-axis is also referred to as the optical axis of the system.  The x-axis is defined as a line that is perpendicular to both the y-axis and z-axis.  The axial plane is defined as a plane spanned by the x-axis and the z-axis, and the transaxial plane is defined as a plane spanned by the y-axis and z-axis.  The ideal x-ray screen and camera sensor are parallel to the axial plane and perpendicular to the optical axis.  The left diagram in Fig.~\ref{fig:global_coord_misaligned} shows the global coordinate system with the ideal x-ray screen and ideal camera sensor.  

\begin{figure}[ht]
\centering
\includegraphics[scale=1]{global_coordinates_misaligned.eps}
\caption{ (a): The global coordinate system.  (b): The eight global parameters that are used to describe the CT system, where the ideal x-ray screen and ideal camera sensor are treated as one unit and are described by one set of global misalignment position and orientation parameters ($d_x, d_z, \theta_x, \theta_y, \theta_z$) with one additional optical magnification factor $M$ that is used to scale down the x-ray screen onto the camera sensor by the lens.  The distance between the x-ray source and the ideal x-ray screen is defined as $R$, and the distance between the x-ray source and the rotation axis is $R_f$.}
\label{fig:global_coord_misaligned}
\end{figure}

When we define the global coordinate system, we have assumed that the x-ray source is infinitesimally small and does not change with the tube current or voltage.  In reality, the x-ray focal spot has a finite size as shown in Chapter~\ref{chap:design_construction}.  Its size increases with both kVp and mAs due to the amount of heat load on the anode material.  Knowing that the size is finite and changing, we still made this assumption because the calibration method is insensitive to the focal spot size change.  In addition, we can use the calibration parameters obtained at one x-ray tube setting to other techniques (i.e. different mAs). 

Next, we need to choose a set of geometric parameters that can be used to define the CT system.  These parameters will be used later in the reconstruction algorithm.  Although each component in the system can potentially have up to six degrees of freedom, it is not always necessary to treat each component individually and to use all six variables for every component.  Instead, we can define a smaller set of global parameters that summarizes the overall geometry of the system by making some simple assumptions.  The first assumption is that the lens focuses every point on the x-ray screen within the lens' field-of-view onto the camera sensor.  This condition eliminates any misalignment between the x-ray screen, the lens, and the camera.  As a result, we can describe the misalignment of these three components as one detector unit.  We can also assume that the x-ray screen is large enough so that any lateral shift in its plane does not change the final image on the camera sensor.  These assumptions allow us to decrease the set of calibration parameters to eight values.

The right diagram in Fig.~\ref{fig:global_coord_misaligned} shows the eight global parameters that are used to describe the CT system.  The detector unit is defined as the combination of the x-ray screen, lens, and camera, where the x-ray screen plane is conjugate to the camera sensor plane with a magnification factor $M$ set by the lens.  The optical axis passes through the center of the x-ray unit and is defined as the center of the camera sensor magnified back onto the x-ray screen.  The eight global parameters are: $R$, $R_f$, $d_x$, $d_z$, $\theta_x$, $\theta_y$, $\theta_z$, and $M$, where $R$ is the distance between the x-ray source and the detector unit, $R_f$ is the distance between the x-ray source and the rotation axis, $d_x$ and $d_z$ are the position misalignments of the center of the detector unit away from the optical axis in either x and z direction respectively, and $\theta_x$, $\theta_y$, and $\theta_z$ are the angular rotations of the detector unit about its respective axes.  These essential parameters are used in the reconstruction algorithm described later in Chapter \ref{chap:reconstruction}

In order to estimate all of the global parameters, we needed to add an additional six parameters to complete our calculation.  These are called nuisance parameters and, just as the name indicates, these parameters are not necessary to define the geometry of the system, however, the calibration method we used required them to be estimated in order to complete our calculation.  These six nuisance parameters are used to describe the position and orientation of the calibration phantom ($x_0, y_0, z_0, \theta^{obj}_x, \theta_y^{obj}, \theta_z^{obj}$) shown in Fig.~\ref{fig:phantom_orientation}.  

\begin{figure}[ht]
\centering
\includegraphics[scale=1]{phantom_orientation.eps}
\caption{The six nuisance parameters that describe the misalignment position and orientation of the phantom.}
\label{fig:phantom_orientation}
\end{figure}

\section{Calibration Method}
\label{section:calibration_method}
We have employed three steps in order to compute all of the global calibration and nuisance parameters, as follows:

\begin{enumerate}
\item Calculate the lens optical magnification power, $M$.
\item Calculate the global parameters, $\theta_x, \theta_y, \theta_z, d_x, d_z, R/R_f$.
\item Calculate the nuisance parameters and find $R$ and $R_f$.
\end{enumerate}

\subsection{Calculate lens magnification power}
\begin{figure}[ht]
\centering
\includegraphics[scale=1]{optical_mag6.eps}
\caption{Procedure for obtaining the optical magnification factor ($M$) using a ruler with a known marker period ($T_{ruler}$) while taking its tilt angle ($\theta$) into consideration}
\label{fig:optical_mag}
\end{figure}
Done under white light, the optical magnification can be measured simply by placing an item of a known size at the x-ray screen and measuring the image size of the object scaled on the sensor.  In practice, a ruler was used as the object of a known size. We measured a small section of the ruler's length at the detector along with its tilt, $\theta$, to calculate the optical magnification power, $M$.  The procedure is illustrated in Fig.~\ref{fig:optical_mag}.
\comment{explain how to get error bar on optical magnification?}
\subsection{Calculate global parameters}

In order to find the global system parameters, we opted to use Smekal's calibration method~\citep{Smekal2004} that derives explicit analytic expressions for a set of fiducial markers.  This method does not require precise knowledge of the marker's spatial location inside the phantom; rather, it uses the marker's projection orbit on a misaligned detector for the calculation.  These orbits are first analyzed using low spatial-frequency Fourier components.  The parameters are then calculated based on each individual point marker from the Fourier coefficients by using a series of equations.  The averages of the parameters over the set of fiducial markers are used as the final result.  The corresponding standard deviations for each parameter are used as error bars in the estimation.

\begin{figure}[ht]
\includegraphics[scale=1]{smekal_system2.eps}
\caption{Calibration steps to calculate global parameters}
\label{fig:smekal_method}
\end{figure}

In this section, we will focus on the main ideas and equations that were used to calculate the calibration parameters.  For more detailed derivations, please refer to the paper~\citep{Smekal2004}.  The system geometry and a graphical representation of the method are shown in Fig.~\ref{fig:smekal_method}, where the global coordinate system and system parameters are defined similar to those given in Fig.~\ref{fig:global_coord_misaligned}. The main idea behind Smekal's method is to first describe the relationship between the point markers and the projection orbit by a set of linear equations based on the rotation matrix of the misaligned detector (step 1). This set of equations is a function of the system parameters and initial marker positions.  Next, the projection orbit is parameterized using a set of Fourier series coefficients (step 2).  Then, it is a matter of finding the relationship between the Fourier series coefficients and the linear equations through various intermediate coefficients in order to disentangle the system parameters while eliminating dependencies on the initial marker positions.

In step 1, we tried to describe the projection orbits of point markers on the misaligned detector using the system parameters.  Shown in Fig.~\ref{fig:smekal_method}, a point on the true misaligned detector $(x', y', z')$, with detector coordinates $(u, v)$, can be written as

\begin{equation}
\begin{aligned}
u \hat{u} + v \hat{v} + \vec{d} =& \, u \mathrm{\mathbf{O}} \hat{x} + v \mathrm{\mathbf{O}} \hat{z} + \vec{d} \\
								=& \, x' \hat{x} + (y' - R + R_f) \hat{y} + z' \hat{z},
\end{aligned}
\label{eq:projection_orbit}
\end{equation}
where $\vec{d} = d_x \hat{x} + d_y \hat{y} + d_z \hat{z}$ is the distance between the center of the ideal detector and the misaligned detector, $\mathrm{\mathbf{O}}$ is a 3 $\times$ 3 rotation matrix that maps the vectors $(\hat{x}, \hat{z})$ to $(\hat{u}, \hat{v})$ using $\theta_x, \theta_y, \theta_z$ shown in Eq.~\ref{eq:rotation_matrix}.
\begin{equation}
\mathrm{\mathbf{O}} = 
\begin{pmatrix}
cos\, \theta_y \, cos \,\theta_z - sin \, \theta_y \, sin \, \theta_x \, sin \, \theta_z & -cos \, \theta_x \, sin \, \theta_z & -cos \, \theta_z \, sin \, \theta_y - cos \, \theta_y \, sin \, \theta_x \, sin \, \theta_z \\
cos \, \theta_z \, sin \, \theta_y \, sin \, \theta_x + cos \, \theta_y \, \sin \, \theta_z & cos \, \theta_x cos \, \theta_z & cos \, \theta_y \, cos \, \theta_z \, sin \, \theta_x - sin \, \theta_y \, sin \, \theta_z \\
cos \, \theta_x \, sin \, \theta_y & -sin \, \theta_x & cos \, \theta_y \, cos \, \theta_x \\
\end{pmatrix}
\label{eq:rotation_matrix}
\end{equation}

Generally speaking, it is not ideal to describe the point $(u, v)$ using the coordinate $(x', y', z')$, i.e. $y' \neq R - R_f$.  Instead, we can describe the point using the ideal coordinate $(u^{id}, v^{id})$ where this perfect alignment counter part (i.e. $y' = R - R_f$) connects the rays from the x-ray source, through the focus, and to the points $(x', y', z')$ using the equation,
\begin{equation}
x' = \frac{y' + R_f}{R} u^{id}, \; \; \; z' = \frac{y' + R_f}{R} v^{id}.
\label{eq:uid_vid}
\end{equation}

\noindent Inserting Eq.~\ref{eq:uid_vid} into Eq.~\ref{eq:projection_orbit}, we can obtain the ideal orbit in terms of the real orbit on the misaligned detector as
\begin{equation}
\begin{pmatrix}
u^{id} \\
v^{id} 
\end{pmatrix} = \frac{R}{R'_y + o_{21}u + o_{23} v} 
\left(
\begin{pmatrix}
o_{11} & o_{13} \\
o_{31} & o_{33} \\
\end{pmatrix} 
\begin{pmatrix}
u \\
v
\end{pmatrix} + 
\begin{pmatrix}
d_x \\
d_z
\end{pmatrix}
\right)
\label{eq:ideal_orbit_matrix}
\end{equation}
\noindent Thus, the inverse relationship for the real orbit in terms of the ideal orbit for Step 1 can be obtained by using some matrix manipulations, and the result is as follows:
\begin{equation}
\begin{pmatrix}
u \\
v
\end{pmatrix} = \frac{1}{det \, \mathrm{\mathbf{Q}}}
\begin{pmatrix}
o_{33} - o_{23} v^{id}/R & -(o_{13} - o_{23} u^{id}/R \\
-(o_{31} - o_{21} v^{id}/R) & o_{11} - o_{21} u^{id}/R \\
\end{pmatrix}
\times 
\begin{pmatrix}
u^{id'} - d_x \\
v^{id'} - d_z
\end{pmatrix}
\label{eq:misaligned_orbit_matrix}
\end{equation}
where, 
\begin{equation}
\begin{pmatrix}
u^{id'} \\
v^{id'}
\end{pmatrix} = \frac{R'_y}{R}
\begin{pmatrix}
u^{id}\\
v^{id}
\end{pmatrix}
\end{equation}
and the determinant in Eq.~\ref{eq:misaligned_orbit_matrix} is given as
\begin{equation}
\begin{aligned}
det \, \mathrm{\mathbf{Q}} \, = \, &(o_{11} - o_{21} u^{id}/R) (o_{33} - o_{23} v^{id}/R) \\
                           - &(o_{13} - o_{23} u^{id}/R) (o_{31} - o_{21} v^{id}/R ).
\end{aligned}
\label{eq:detQ}
\end{equation}

In Step 2, we need to parameterize the point marker's projection orbit on the misaligned detector using the Fourier coefficients.  We can write the discrete real Fourier series as follows, 
\begin{equation}\label{eq:fourierseries}
u_n = \frac{U_0}{2} + \sum ^{N/2-1}_{k=1} (U_k \cos (k\alpha_n)) + \tilde{U}_k \sin (k \alpha_n) + (-1)^{(n-1)} \frac{U_{N/2}}{2}, 
\end{equation}

\noindent with similar expressions for $v_n$.  The real Fourier coefficients are given by:

\begin{equation}\label{eq:fouriercoeff}
\begin{split}
U_k = & \frac{2}{N}\sum_{n=1}^{N} u_n \cos (k \alpha_n), \hspace{0.3cm} k = 0, ...., N/2, \\
\tilde{U}_k = & \frac{2}{N} \sum_{n=1}^{N} u_n \sin (k \alpha_n), \hspace{0.3cm} k = 1,...,N/2-1
\end{split}
\end{equation}

\noindent and analogously for $V_k$ and $\tilde{V_k}$.  Only the first three Fourier components were needed in the misalignment calculation.  Thus, the method is insensitive to high frequency fluctuations and uncertainties that stem from marker-point extraction between different projection angles.  These Fourier coefficients and the results from Step 1 are used to calculate the final system parameters by going through some intermediate equations.  These equations are shown in Appendix X.

The result of Smekal's method calculates ten parameters.  These are the detector rotation misalignment, $\theta_x$,$\theta_y$,$\theta_z$, detector position misalignment, $d_x$,$d_z$, $R$, and $R_y'$, where $R_y' = R + d_y$.  This method also provides the object marker initial location with respect to $R_f$, i.e., $x_0/R_f$, $y_0/R_f$, $z_0/R_f$.  Unfortunately, $R_f$ and marker initial locations are presented together and can no longer be separated using Smekal's calibration method.  To overcome this problem, we used the contracting grid algorithm to search for $R_f$.  In order to complete this last step, we need to estimate the six nuisance parameters, $\theta_x^{obj}, \theta_y^{obj}, \theta_z^{obj}, x_0, y_0, z_0$.

%\begin{figure}
%\centering
%	\begin{subfigure}[b]{0.4\linewidth}
%	\centering
%	\placeholderimage[width=3cm,height=2cm]{FourierFit.png}
%	\label{fig:FourierFit}
%	\caption{Fourier coefficient fit to data}
%	\end{subfigure}
%\hspace{0.2cm}
%	\begin{subfigure}[b]{0.4\linewidth}
%	\centering
%	\placeholderimage[width=3cm,height=2cm]{smekalresult.png}
%	\label{fig:smekalresult}
%	\caption{Calculated result}
%	\end{subfigure}
%\label{fig:smekal_method}	
%\caption{Fitting result}
%\end{figure}

\subsection{Calculating the nuisance parameters}
The contracting grid algorithm is based on maximum-likelihood estimation.  The maximum-likelihood method can generally be formulated as a search over parameter space as
\begin{equation}
\label{eq:mlem}
\mathrm{\boldsymbol{\hat{\theta}}} = \arg\max_{\mathbf{\theta}} \; \mathrm{\lambda (\boldsymbol{\theta} | \mathbf{g})} = \arg\max_{\theta} \; \mathrm{pr( \mathbf{g}|\boldsymbol{\theta})},
\end{equation}

\noindent where $\boldsymbol{\theta}$ is a vector of the interested parameters, $\mathbf{g}$ is the data vector, $\lambda$ is the likelihood of observing $\mathbf{g}$, and $\boldsymbol{\hat{\theta}}$ is a vector of estimated parameters.  Equation~\ref{eq:mlem} can be stated as a question: given a set of data, or observations $\mathbf{g}$, find the set of parameters $\boldsymbol{\theta}$ that has the highest probability of creating this set of observed data.  The data set, $\mathbf{g}$, in our case are the projection points of the markers on the misaligned detector. The parameter vector $\boldsymbol{\theta}$ is the object misalignment position and orientation and the system parameter, $R_f$.  

Given an imaging system and object model, we can express the results from the imaging system using a general equation:
\begin{equation}
\label{eq:gHf}
\mathbf{g} = \mathbf{H} \; \mathbf{f} + \mathrm{n}
\end{equation}
where $\mathrm{n}$ is additive noise associated with the image system, $\mathbf{f}$ is the object vector, $\mathbf{g}$ is the image vector, and $\mathbf{H}$ is the imaging system operator that takes the object information to create $\mathbf{g}$.  If we average multiple images of the same object, we arrive at the mean image, $\mathbf{\bar{g}}$ with
\begin{equation}
\label{eq:gbar}
\mathbf{\bar{g}} = \mathbf{H} \; \mathbf{f}.
\end{equation}

When we acquire real CT image data with reasonably long exposure time, the noise term, $\mathrm{n}$, can be assumed as a normal distribution function with zero mean.  Thus, the image data, $\mathbf{g}$, can also be assumed to be normally distributed with mean $\mathbf{\bar{g}}$.  We can rewrite the likelihood as a zero-mean Gaussian distribution function.  The maximum-likelihood solution to a zero-mean Gaussian function is then reduced to solve
\begin{equation}
\arg\min_{\theta} \| \mathbf{g} - \mathbf{\bar{g}} \|^2,
\label{eq:least_square}
\end{equation}
which is equivalent to the least-squares solution.  In other words, find the parameter vector $\boldsymbol{\theta}$ that minimizes the mean-squared difference between the observed data, $\mathbf{g}$, and the parameter-dependent mean, $\mathbf{\bar{g}}$, calculated using $\mathbf{H}$.  

The method to search for the vector $\boldsymbol{\theta}$ that resides in a multi-dimensional space is called the contracting-grid algorithm, which is an iterative search technique.  Just as it sounds, at each iteration the method generates a ``grid'' for each parameter, and searches through the grid to find the best parameter combinations.  The next iteration ``contracts'' the grid around each parameter and the search repeats until the algorithm reaches a preset number of iterations.
%Common methods to solve for a multi-dimensional vector includes conjugate gradient methods and a host of many others (Kolda2003, Knuth1998, Audet2006, Kolda2003, Conn2008).  We have opted to use the contracting grid search algorithm that allows identification of a function's maximum (or minimum) in a fixed number of iterations.  It is a deterministic search algorithm (so the same starting point always yields the same result compared to statistical search methods where the end result is always slightly different).  Essentially the algorithm is a semi exhausted search for a set of parameters that minimizes the MSE, then the algorithm regenerate another set of parameter sets based on the previous iteration until we reach the maximum iteration specified. 
%\comment{talk about prior? we know a guess right? guess a prior parameter. this is not the same as $pr(\theta)$}
The contracting-grid algorithm can broken down into five steps:
\begin{enumerate}
\item For each parameter $\theta_i$, create a region of physically reasonable grid size $M_i$.
\item Use Eq.~\ref{eq:least_square} and calculate the least-squared results of all parameter grid combinations.
\item Find the set of parameters that generated the lowest least-squared result.
\item Contract the grid size for each parameter.
\item Repeat Steps 2-4 until the algorithm reaches a preset number of iterations.
\end{enumerate}
%\comment{ Include parameter grid sizes as a table?}
For more detailed information regarding the contracting-grid search algorithm, please refer to the paper by Jacob Y. Hesterman~\citep{Hesterman2010}.  

Through experimentation, we have found that it is more efficient to first obtain a rough estimate of the parameters, $R_f$, $\theta^{obj}_z$, $\theta^{obj}_x$, and $\theta^{obj}_y$ ,before fully indulging into the contracting-grid algorithm.  A rough estimation of $R_f$ can simply be found by using the vertical separation between the point markers on the projection image ($\Delta z_0$) of a known phantom and applying it to the values $\Delta z_0/R_f$ calculated from the previous section.  $\theta^{obj}_x$ is the initial rotation orientation of the point markers about the z-axis, changing this value does not affect the overall projection locations of the point markers but it does greatly contribute to the least-squares sum of the contracting-grid algorithm.  Therefore, we tried to approximate its value in order to minimize the search duration later.  Finally, the values for $\theta_x^{obj}$ and $\theta_y^{obj}$ are iterated over 360$\degree$ to obtain a rough approximation.  

\subsection{Calibration results}
\label{subsect:cali_results}
Figure~\ref{fig:calibration_plot} shows the projections of the ball bearings from experiment vs. the projections of point markers using the calibration parameters.  We used 100 contracting-grid iterations with a grid size of four for each parameter at a contracting rate of 1.05.

\begin{figure}[h]
\includegraphics[scale=0.7]{calibration_plot.eps}
\caption{Projection of the ball bearings from experiment vs. the projection of the point markers using the calibration parameters after 100 iterations with a grid size of 4 and a contracting rate of 1.05.}
\label{fig:calibration_plot}
\end{figure}

Table~\ref{table:calibration_result} shows the calibration results of the CT system.  Note that because $R_f$ is calculated using the contracting-grid algorithm, we cannot measure its standard deviation.  The most important angular measurement is $\theta_y$ because it accounts for the image rotation about the optical axis.  Errors in this parameter can result in severe artifacts in the reconstruction image.  Both $\theta_x$ and $\theta_z$ are less important; in fact, these values were assumed to be zero in some calibration methods~\citep{Noo2000, Cho2005, Yang2006}.  

\begin{center}
	\begin{table}[ht]\caption{Calibration Results}
		\begin{tabular}{c | c | r}
		\hline
		Parameter &	Value & Standard Deviation \\ \hline \hline
		$R$ & 1106.3 (mm) & 2.43 (mm)\\ \hline
		$R_f$ & 900.7 (mm)&  NA \\ \hline
		$d_x$ & 4.01 (mm)& 0.0028 (mm)\\ \hline
		$d_z$ & -1.40 (mm)& 0.10 (mm)\\ \hline
		$\theta_x$ & -0.019 (radians)& 1.0743 (radians)\\ \hline
		$\theta_y$ & 0.0039 (radians)& 0.0003 (radians)\\ \hline
		$\theta_z$ & -0.0047 (radians)& 0.0089 (radians)\\ \hline	
		$M$ & 13.1 & 0.24 \\ \hline
		\end{tabular}
	\end{table}
	\label{table:calibration_result}
\end{center}

\section{Calibration Phantom}
The phantom used in the calibration process was designed in SolidWorks and printed using the rapid prototype machine here at CGRI.  The phantom is composed of two separate pieces, a larger bracket that is used to mount to the rotation stage, and a smaller insert where various number of ball bearings and sizes can be attached.  These are shown in Fig.~\ref{fig:calibration_phantom}.

The bracket is designed so that the center of the ball bearings on the inserts are 60 mm from the center of the rotation axis on the bracket.  The smaller insert has a conical end so it is easy to align the vertical axis of the markers against the bracket holder.  The ball bearings are made out of stainless steel and are purchased from McMaster-Carr.  Three different bearing sizes (1/16 \inches, 1/8 \inches and 3/16 \inches and 1/4 \inches) were purchased and tested.  Through experiment we have found that 1/8 \inches bearing worked the best.
\begin{figure}[ht]
	\begin{subfigure}[b]{0.3\linewidth}
	\includegraphics[width = 4cm]{phantom_bracket_clip.png}
	\label{fig:calibration_phantom_bracket}
	\caption{}
	\end{subfigure}
\hspace{0.2cm}
	\begin{subfigure}[b]{0.3\linewidth}
	\includegraphics[width = 4cm]{phantom_insert2_crop.png}
	\label{fig:calibration_phantom_insert}
	\caption{}
	\end{subfigure}
\caption{(a) calibration phantom bracket, (b) inserts with different ball bearings}
\label{fig:calibration_phantom}
\end{figure}

\subsection{Extract phantom marker locations}
In order to use the calibration method described in section~\ref{section:calibration_method}, we must be able to extract the 2-dimensional coordinate location of the point markers on the detector using the phantom ball bearing projection images.  The raw projection image at one angle is shown in Fig.~\ref{fig:calibration_projection}.

\begin{figure}[ht]
\centering
\includegraphics[width = 10cm]{calibration_projection_w_label}
\caption{Projection of the calibration phantom at one angle.  The image taken used 100 kV x-ray at 200 $\mu A$ with 2 second exposure time.}
\label{fig:calibration_projection}
\end{figure}

Upon close inspection, although we can see the ball bearings clearly, the image is littered with small clusters of very ``hot'' pixels, also shown in Fig.~\ref{fig:calibration_projection}.  These clusters of bright pixels are the result of direct x-ray interactions with the sCMOS detector material, where the x-ray energies are deposited inside the detector resulting in very high detector value.  The location of these cluster are random and vary from image to image, typically higher x-ray tube energies (>60 kVp) produces more clusters than lower x-ray tube energies.  However we wish to calibrate using higher x-ray tube energy because the projection image has a higher contrast difference between the steel ball bearing and the plastic phantom material which allows us to extract the ball bearing location more easily.  Fortunately, we can eliminate the majority of these high-value clusters by thresholding the entire image.  The resulting is an intermediate image with most of the phantom structures removed as well as the majority of these high-value clusters, leaving only the clusters of ball bearing projections and other smaller clusters left-over from the phantom structures.  Unfortunately at this stage, we cannot simply use well-known clustering algorithms such as \textit{k-mean} to extract the centroid locations because the left-over noise are simply too numerous for us to identify the \textit{k} value, a.k.a. the number of clusters in the image.  Instead we use a slightly more tedious method to search for each ball bearing projection cluster iteratively.  This method can be summarized by the following steps:
\begin{enumerate}
\item \label{sort:1} Sort all points in the main image array by their coordinates.
\item \label{sort:2} Retrieve the first point's x-y coordinate.
\item \label{sort:3} Identify the next point that is closest to the first point within a small distance.
\item \label{sort:4} Calculate an equivalent coordinate, the center-of-mass (COM) point using the neighboring points
\item \label{sort:5} Iterate through all points and repeat step~\ref{sort:3}-\ref{sort:4} until we've roughly identified all points that are close to each other
\item \label{sort:6} Recalculate the coordinate for COM point using all of the points identified in step~\ref{sort:5}, then iterate through all points again in the main image array to make sure we did not miss any points for this cluster.
\item \label{sort:7} Recalculate the center-of-mass point based on this newly identified cluster of points.
\item \label{sort:8} Reject this cluster if it is too small in terms of size or the number of points.
\item \label{sort:9} Record the COM as the cluster centroid, remove this cluster of points from the main image array.
\item \label{sort:10} Repeat step~\ref{sort:2}-\ref{sort:9} until image cluster size reaches zero.
\end{enumerate}

The main idea for this method is to assume that points close to each other belong in the same cluster.  This is the reasoning behind step \ref{sort:1} where we needed to sort all points by their coordinate position first.  We reason that after all points are sorted, then if we iteratively go through all points in the main array, all points that are within a cluster should be very close to each other.  We use the center-of-mass point as a reference to determine whether if the next point should be included in the current cluster.  The criteria for this determination is distance.  If the distance between the COM and the next point is close, then we classify the next point as a cluster point, and repeat until we have searched iteratively through all points in the image array, step~\ref{sort:2}-\ref{sort:6}.  Once a cluster is identified, we look through all the points in the array once more to double check and make sure we have not missed any points that should have belonged in this cluster (step~\ref{sort:7}).  Once this cluster is identified, we classify this cluster as either a ball bearing projection cluster, or a background noise cluster based on how many points are in this cluster and the cluster size (step~\ref{sort:8}).  A secondary array maps the points in the image array to the newly identified cluster so these points are not used when the algorithm repeats step~\ref{sort:2}-\ref{sort:9} in search for a new cluster.  Since this method iterates through the main image array twice for each cluster, outwardly it can be a very slow method.  However since we remove all points in the cluster each time a cluster is identified, the method speeds up as more clusters are found.  In fact, once the raw projection image is thresholded (before using this method).  We are left with only approximately 10,000 to 30,000 points, which is very manageable with MATLAB.  In the end this method only takes about 1-2 seconds to identify and calculate the centroid coordinates in each raw calibration image.  The calibration code can be downloaded from my git public repository: \hyperref[]{\url{https://bitbucket.org/hxfan/matlab_calc}}.

Figure~\ref{fig:clustering_algorithm} provides a graphical description of the clustering algorithm we have described in this section.  In this figure, each point represent a point from the projection image after thresholding.  The number above each point represents their rank order after the points are sorted by the coordinate position (y coordinate).  The center-of-mass point is used as a reference to find the next cluster point, and it is re-calculated after the next cluster point is identified.  Shown in the figure, once the 6th cluster point is identified, the distance between the center-of-mass point and point 7 exceeds $R_{point \; cluster}$, therefore point 7 and 8 does not belong to cluster 1 and will not be used to calculate the next center-of-mass point.  Also shown is the center-of-mass point after point 24 is identified. The distance $d_3$ between center-of-mass point and point 25 exceeds $R_{point \; cluster}$ therefore point 25 is also ruled out and does not belong to cluster 1.  Cluster 2 includes point 7, 8, 13, and 14 however this cluster is too small so it is classified as noise cluster.  Point 25 is by itself therefore ruled out as belonging to any cluster.  Cluster 1 and cluster 3 are classified as ball bearing projection clusters with corresponding centroid positions.

\begin{figure}[ht]
\centering
\includegraphics[scale=1.2]{clustering_algorithm}
\caption{A graphical description of the clustering algorithm.  Here the number above each point indicates their rank order after the points are sorted according to the sort direction.  $R_{point \; cluster}$ is a predetermined distance after looking through the raw calibration image.  The center-of-mass point is re-calculated after each cluster point is identified.  After the center-of-mass point is recalculated once point 6 is identified, the distance $d_1$ is much greater than $R_{point \; cluster}$, therefore point 7 and 8 are ruled out from cluster 1, as well as point 13 and 14.  Point 25 is also ruled out because $d_3$ is much greater than $R_{point \; cluster}$ after center-of-mass point is recalculated once point 24 is identified.  Cluster 2 is classified as noise cluster because it does not have enough points within the cluster.  Cluster 3 is identified as a ball bearing projection cluster because of its size and the number of points within the cluster.}
\label{fig:clustering_algorithm}
\end{figure}

\comment{ Should I provide an example using real calibration image? }

\section{Summary}
In this chapter we have described the calibration method for the prototype CT system.  We begin by providing an overview of some of the existing methods for calibrating bench-top x-ray CT systems.  Then we followed by defining the geometry of the system and describing the steps that were taken to extrapolate all 14 parameters of the system.  The final result of the system parameters are shown in section~\ref{subsect:cali_results}.  The last two sections of this chapter were dedicated to describing the physical calibration phantom and the algorithm that were used to extract the ball bearing projection points from raw calibration images.  

%
%\begin{equation}\label{eq:d_coeff}
%\begin{split}
%d_{22}' =& \; (U_3^2 - U_1^2 + \tilde{U}_3^2 - \tilde{U}_1^2)/2 \\
%d_{20}' =& \; ((U_1 - U_3)\,U_2 - (\tilde{U}_3 - \tilde{U}_1)\tilde{U}_2)/d_{22}' \\
%d_{21}' =& \; ((U_1 + U_3)\tilde{U}_2 - (\tilde{U}_3 + \tilde{U}_1) U_2)/ d_{22}' \\
%d_{00}' =& \; ((U_0 + U_2)\,d_{20}' + \tilde{U}_2 \, d_{21}' + 2 U_1)/2 \\
%d_{01}' =& \; (\tilde{U}_2 \, d_{20}' + (U_0 - U_2)\, d_{21}' + 2 \tilde{U}_1)/2  \\
%d_{02}' =& \; (U_1 d_{20}' + \tilde{U}_1 \, d_{21}' + U_0)/2 \\
%d_{10}' =& \; ( (V_0 + V_2) \, d_{20}' + \tilde{V}_2 \, d_{21}' + 2 V_1 )/2 \\
%d_{11}' =& \; (\tilde{V}_2 d_{20}' + \tilde{V}_2 \, d_{21}' + 2 V_1)/2 \\
%d_{12}' =& \; (V_1 \, d_{20}' + \tilde{V}_1 \, d_{21}' + V_0)/2   \\
%\end{split}
%\end{equation}
%
%\begin{equation}\label{eq:c_coeff}
%\begin{split}
%&
%\begin{pmatrix}
%c_{00}' \\
%c_{01}' 
%\end{pmatrix} = \frac{1}{d_{20}'^2 + d_{21}'^2}
%\begin{pmatrix}
%d_{20}' & d_{21}' \\
%d_{21}' & d_{20}'
%\end{pmatrix}
%\left[ \frac{1}{2}
%\begin{pmatrix}
%U_2 & \tilde{U}_2 \\
%\tilde{U}_2 & -U_2
%\end{pmatrix}
%\begin{pmatrix}
%d_{20}' \\ d_{21}'
%\end{pmatrix}
%+ \begin{pmatrix}
%U_1 \\ \tilde{U_1}
%\end{pmatrix}
%\right]
%+ \begin{pmatrix}
%U_2/2 \\ 0
%\end{pmatrix} \\
%&
%\begin{pmatrix}
%c_{10}' \\ c_{11}'
%\end{pmatrix} 
%= \frac{1}{d_{20}' + d_{21}'^2}
%\begin{pmatrix}
%d_{20}' & d_{21}' \\
%d_{21}' & d_{20}'
%\end{pmatrix}
%\left[ \frac{1}{2}
%\begin{pmatrix}
%V_2 & \tilde{V}_2 \\
%\tilde{V}_2 & -V_2
%\end{pmatrix}
%\begin{pmatrix}
%d_{20}' \\ d_{21}'
%\end{pmatrix}
%+ \begin{pmatrix}
%V_1 \\ \tilde{V_1}
%\end{pmatrix}
%\right]
%+ \begin{pmatrix}
%V_2/2 \\ 0
%\end{pmatrix}
%\end{split}
%\end{equation}
%
%\begin{equation}
%\label{eq:eta}
%\tan \eta = - \frac{c_{11}'}{c_{01}'}
%\end{equation}
%
%\begin{equation}
%\label{eq:ABCEF}
%\begin{split}
%A =& \sin \eta \; c_{00}' + \cos \eta \; c_{10}' \\
%B =& \cos \eta \; c_{01}' + \sin \eta \; c_{11}' \\
%C =& \cos \eta \; c_{00}' - \sin \eta \; c_{10}' \\
%E =& \sin \eta \; d_{02}' + \cos \eta \; d_{12}' \\
%F =& \cos \eta \; d_{02}' + \sin \eta \; d_{12}' \\
%\end{split}
%\end{equation}
%
%\begin{equation}
%\label{eq:theta}
%\sin \theta = \frac{B (F_k - F_j)}{(E_k - E_j)(C - F_k)-(F_k - F_j)(A - E_k)}
%\end{equation}
%
%\begin{equation}
%\label{eq:varphi}
%\tan \varphi = \frac{C-F}{\sin \theta \, (A-E) \, \pm \, B}
%\end{equation}