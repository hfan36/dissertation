\chapter{GEOMETRICAL CALIBRATION OF THE CT SYSTEM}
\label{chap:calibration}

\section{Background}
The geometry of the computed tomography system can be described using a set of global parameters.  These parameters are crucial for the reconstruction algorithm in order to provide the best object resolution.  Since it is impossible to know precisely the geometry of the system after assembly, a calibration method is needed in order to calculate these system parameters and to account for misalignment of the system prior to image reconstruction.  

In tomography, it is well known that using inaccurate parameters can produce severe artifacts~\citep{Li1994a, Li1994b, Wang1998}. Methods for estimating geometrical parameters of tomographic scanners have been investigated by many groups since 1987, starting with Gullberg~\citep{Gullberg1987}.  Some calibration methods tend to be specific to the 2-dimensional parallel-beam geometry~\citep{Azevedo1990, Busemann1987}; others are only for 2-dimensional fan-beam geometry~\citep{Crawford1988, Hsieh1999, Gullberg1987}.  In these earlier methods, the overall approach to calibration is to estimate the geometric parameters by first measuring the locations of point objects on the detector and determining the analytic expressions for these point-object locations as functions of the unknown scanner parameters and unknown positions of the point objects.  This step provides a set of nonlinear equations, which are then solved using an iterative method such as the Levenberg-Marquard algorithm~\citep{Rougee1993}.  The downside of this method is that the algorithms rely heavily on a highly nonlinear parameter-estimation problem and are highly sensitive to the initial estimations and the order in which the parameters are estimated.  There are questions of stability and uniqueness of the parameters.  It is uncertain if local minima exist or if more than one set of calibration parameters can satisfy these equations.  This work was later extended to 3-dimensional cone-beam scanners~\citep{Gullberg1990}; however, the degrees of freedom were restricted, and some shift parameters were assumed to be known.

To avoid initialization and convergence problems created by the Levenberg-Marquard algorithm, many authors have proposed methods that employ direct calculations of the system parameters.  In 1999, a method was proposed by Bronnikov that required only two 180$\degree$-opposed projection images of  a circular aperture.  Later authors such as Noo \textit{et al.}, Yang \textit{et al.}, and Cho \textit{et al.} had similar ideas in which they used a set of intermediate equations to describe the projection-orbit data of fiducial markers~\citep{Noo2000, Yang2006, Cho2005}.  The equations proposed by Noo and Yang were slightly different from each other.  In Cho's case, they used a rapid prototype printer to create a phantom that contains multiple fiducial markers to produce several sets of rings about the rotation axis so that the phantom does not need to be rotated during data acquisition.  However, all of these methods are limited to a restricted set of parameters, usually omitting out-of-plane rotation of the detector.  In 2004, Smekal~\citep{Smekal2004} introduced another analytical method to solve for all system parameters except that some parameters are presented together as ratio rather than individual values.  The advantage of this method is that it is insensitive to the precise extraction of the phantom point projection location on the detector.  In 2008, Panetta~\citep{Panetta2008} proposed a new method in which they measured the misalignment parameters of a cone-beam scanner by minimizing a geometry-dependent cost function.  This cost function is computed from the projection data of a generic object; hence, no a-priori knowledge of the object shape or position is required.  In 2011, Jared Moore used maximum-likelihood expectation-maximization (MLEM) algorithm to estimate all system parameters by calculating the projection of a known phantom at two 90$\degree$-opposed angles.

In the next section, we will describe the calibration method that was used for the prototype x-ray CT system.  We will first define the global coordinate system, then we will describe the steps and methods that were used to find all system calibration parameters.

\section{Defining Geometric Parameters}
A global coordinate system is used to describe the scan geometry of the CT system, and a local coordinate axis is later used to describe the points on the misaligned detector.  The z-axis is defined as the rotation axis of the object and is set by the rotation stage; the y-axis is defined as a perpendicular line to the z-axis.  It passes through the x-ray source and through the ideal x-ray screen plane and camera sensor plane, where both are ideal in the sense that they are perpendicular to the y-axis.  The y-axis is also referred to as the optical axis of the system.  The x-axis is defined as a line that is perpendicular to both the y-axis and z-axis.  Fig.~\ref{fig:global_coord_misaligned}a shows the global coordinate system with the ideal x-ray screen plane and ideal camera sensor plane.  

\begin{figure}[ht]
\centering
\includegraphics[scale=1]{global_coordinates_misaligned.eps}
\caption{ (a): The global coordinate system.  (b): The eight global parameters that are used to describe the CT system, where the ideal x-ray screen and ideal camera sensor are treated as one unit and are described by one set of global misalignment position and orientation parameters ($d_x, d_z, \theta_x, \theta_y, \theta_z$) with one additional optical magnification factor $M$ that is used to scale down the x-ray screen onto the camera sensor by the lens.  The distance between the x-ray source and the ideal x-ray screen is defined as $R$, and the distance between the x-ray source and the rotation axis is $R_f$.}
\label{fig:global_coord_misaligned}
\end{figure}

When we define the global coordinate system, we have assumed that the x-ray source is infinitesimally small and does not change with the tube current or voltage.  In reality, the x-ray focal spot has a finite size as shown in Chapter~\ref{chap:design_construction}.  Its size increases with both kVp and mAs.  Knowing that the size is finite and changing, we still made this assumption because the calibration method is insensitive to the focal spot size change.  In addition, we can apply the calibration parameters obtained at one x-ray tube setting to other techniques (i.e. different mAs). 

Next, we need to choose a set of geometric parameters that can be used to define the CT system.  These parameters will be used later in the reconstruction algorithm.  Although each component in the system can potentially have up to six degrees of freedom, it is not always necessary to treat each component individually and to use all six variables for every component.  Instead, we can define a smaller set of parameters that summarizes the overall geometry of the system by making some simple assumptions.  The first assumption is that the lens focuses every point on the x-ray screen within the lens' field-of-view (FOV) onto the camera sensor.  We made this assumption because we expect the lens to be well corrected for distortion, at least within the center of FOV.  Since the lens is designed for a full-framed sensor, distortion on a smaller sensor, such as the Andor Neo is minimum.  In addition, we only use the center part of the image for calibration, we have ignored lens distortion.  This condition eliminates any misalignment between the x-ray screen, the lens, and the camera.  As a result, we can describe the misalignment of these three components as one detector unit.  In practice, we cannot change the alignment between the lens and camera as they are fitted together using a mechanical mount (Nikon F-mount), and we have not noticed any distortion in the calibration images we have taken using the Andor Neo camera.  In addition, the commercial Nikon lens has a large enough depth of focus that we did not perceive any defocus within the field of view on the phosphor screen for the camera positions that we have used.


We have also assumed that the x-ray screen is large enough so that any lateral shift in its plane does not change the final image on the camera sensor.  These assumptions allow us to decrease the set of calibration parameters to eight values.

Fig.~\ref{fig:global_coord_misaligned}b shows the eight global parameters that are used to describe the CT system.  The detector unit is defined as the combination of the x-ray screen, lens, and camera, where the x-ray screen plane is conjugate to the camera sensor plane with a magnification factor $M$ set by the lens.  The optical axis passes through the center of the x-ray unit and is defined as the center of the camera sensor magnified back onto the x-ray screen.  The eight global parameters are: $R$, $R_f$, $d_x$, $d_z$, $\theta_x$, $\theta_y$, $\theta_z$, and $M$, where $R$ is the distance between the x-ray source and the detector unit, $R_f$ is the distance between the x-ray source and the rotation axis, $d_x$ and $d_z$ are the position misalignments of the center of the detector unit away from the optical axis in either x and z direction respectively, and $\theta_x$, $\theta_y$, and $\theta_z$ are the angular rotations of the detector unit about its respective axes.  These essential parameters are used in the reconstruction algorithm described later in Chapter~\ref{chap:reconstruction}.

In order to estimate all of the global parameters, we needed to add an additional six parameters to complete our calculation.  These are called nuisance parameters and, just as the name indicates, these parameters are not necessary to define the geometry of the system, however, the calibration method we used required them to be estimated in order to complete our calculation.  These six nuisance parameters are used to describe the position and orientation of the calibration phantom ($x_0, y_0, z_0, \theta^{obj}_x, \theta_y^{obj}, \theta_z^{obj}$) shown in Fig.~\ref{fig:phantom_orientation}.  

\begin{figure}[ht]
\centering
\includegraphics[scale=1]{phantom_orientation.eps}
\caption{The six nuisance parameters that describe the misalignment position and orientation of the phantom.}
\label{fig:phantom_orientation}
\end{figure}

\section{Calibration Method}
\label{section:calibration_method}
We have employed three steps in order to compute all of the calibration and nuisance parameters, as follows:

\begin{enumerate}
\item Calculate the lens optical magnification power, $M$.
\item Calculate the majority of global parameters using Smekal's method, which include $\theta_x, \theta_y, \theta_z, d_x, d_z$, and $R$.
\item Calculate the nuisance parameters ($x_0, y_0, z_0, \theta^{obj}_x, \theta^{obj}_y, \theta^{obj}_z$) and find $R_f$.
\end{enumerate}

\subsection{Calculate lens magnification power}
\begin{figure}[ht]
\centering
\includegraphics[width = 9cm]{Edmund_target.JPG}
\caption{Resolution chart from Edmund Optics.}
\label{fig:edmund_target}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[scale=1]{optical_mag7.eps}
\caption{Procedure for obtaining the optical magnification factor ($M$) using Edmund Optics' resolution chart.}
\label{fig:optical_mag}
\end{figure}
The optical magnification can be measured under white light by placing an item of a known size at the phosphor screen and measuring the image size of the object scaled on the sensor.  In practice, we used a resolution chart purchased from Edmund Optics, shown in Fig.~\ref{fig:edmund_target} and focused our camera on the 1 line per mm bar section of the resolution chart.  For each row of the image, we fitted the data to the first order of the Fourier series using the ``fit()'' function in MATLAB.  The phase shift of each row of the image corresponds to the bar target rotation.  Once the image is corrected for rotation by use ``imrotate()'' function, we can then average the image over rows and calculate the period of the bar target.  This procedure is illustrated in Fig.~\ref{fig:optical_mag}.

\subsection{Calculate global parameters}

In order to find the global system parameters, we opted to use Smekal's calibration method~\citep{Smekal2004} that derives explicit analytic expressions for a set of fiducial markers.  This method does not require precise knowledge of the marker's spatial location inside the phantom; rather, it uses the marker's projection orbit on a misaligned detector for the calculation.  These orbits are first analyzed using low spatial-frequency Fourier components.  The parameters are then calculated based on each individual point marker from the Fourier coefficients by using a series of equations.  The averages of the parameters over the set of fiducial markers are used as the final result.  The corresponding standard deviations for each parameter are used as error bars in the estimation.
%
\begin{figure}[ht]
\includegraphics[scale=1]{smekal_system3.eps}
\caption{Calibration steps to calculate global parameters.}
\label{fig:smekal_method}
\end{figure}

In this section, we will focus on the main ideas and equations that were used to calculate the calibration parameters.  Detailed derivations are given in the paper~\citep{Smekal2004}.  The system geometry and a graphical representation of the method are shown in Fig.~\ref{fig:smekal_method}, where the global coordinate system and system parameters are defined similar to those given in Fig.~\ref{fig:global_coord_misaligned}. The main idea behind Smekal's method is to first describe the relationship between the point markers and the projection orbit by a set of linear equations based on the rotation matrix of the misaligned detector (step 1). This set of equations is a function of the system parameters and initial marker positions.  Next, the projection orbit is parameterized using a set of Fourier series coefficients (step 2).  Then, it is a matter of finding the relationship between the Fourier series coefficients and the linear equations through various intermediate coefficients in order to disentangle the system parameters while eliminating dependencies on the initial marker positions.

In step 1, we can describe the projection orbits of point markers on the misaligned detector using the system parameters.  Shown in Fig.~\ref{fig:smekal_method}, a point on the true misaligned detector $(x', y', z')$, with detector coordinates $(u, v)$, can be written as,
%
\begin{equation}
\begin{aligned}
u \hat{u} + v \hat{v} + \vec{d} =& \, u \mathrm{\mathbf{O}} \hat{x} + v \mathrm{\mathbf{O}} \hat{z} + \vec{d} \\
								=& \, x' \hat{x} + (y' - R + R_f) \hat{y} + z' \hat{z},
\end{aligned}
\label{eq:projection_orbit}
\end{equation}
%
where $\vec{d} = d_x \hat{x} + d_y \hat{y} + d_z \hat{z}$ is the distance between the center of the ideal detector and the misaligned detector, $\mathrm{\mathbf{O}}$ is a 3 $\times$ 3 rotation matrix that maps the vectors $(\hat{x}, \hat{z})$ to $(\hat{u}, \hat{v})$ using $\theta_x, \theta_y, \theta_z$ shown in Eq.~\ref{eq:rotation_matrix}.
%
\begin{equation}
\mathrm{\mathbf{O}} = 
\begin{pmatrix}
cos\, \theta_y \, cos \,\theta_z - sin \, \theta_y \, sin \, \theta_x \, sin \, \theta_z & -cos \, \theta_x \, sin \, \theta_z & -cos \, \theta_z \, sin \, \theta_y - cos \, \theta_y \, sin \, \theta_x \, sin \, \theta_z \\
cos \, \theta_z \, sin \, \theta_y \, sin \, \theta_x + cos \, \theta_y \, \sin \, \theta_z & cos \, \theta_x cos \, \theta_z & cos \, \theta_y \, cos \, \theta_z \, sin \, \theta_x - sin \, \theta_y \, sin \, \theta_z \\
cos \, \theta_x \, sin \, \theta_y & -sin \, \theta_x & cos \, \theta_y \, cos \, \theta_x \\
\end{pmatrix}
\label{eq:rotation_matrix}
\end{equation}

Generally speaking, it is not ideal to describe the point $(u, v)$ using the coordinate $(x', y', z')$, i.e. $y' \neq R - R_f$.  Instead, we can describe the point using the ideal coordinate $(u^{id}, v^{id})$ where this perfect alignment counter part (i.e. $y' = R - R_f$) connects the rays from the x-ray source, through the focus, and to the points $(x', y', z')$ using the equation,
%
\begin{equation}
x' = \frac{y' + R_f}{R} u^{id}, \; \; \; z' = \frac{y' + R_f}{R} v^{id}.
\label{eq:uid_vid}
\end{equation}
%
Inserting Eq.~\ref{eq:uid_vid} into Eq.~\ref{eq:projection_orbit}, we can obtain the ideal orbit in terms of the real orbit on the misaligned detector as
%
\begin{equation}
\begin{pmatrix}
u^{id} \\
v^{id} 
\end{pmatrix} = \frac{R}{R'_y + o_{21}u + o_{23} v} 
\left(
\begin{pmatrix}
o_{11} & o_{13} \\
o_{31} & o_{33} \\
\end{pmatrix} 
\begin{pmatrix}
u \\
v
\end{pmatrix} + 
\begin{pmatrix}
d_x \\
d_z
\end{pmatrix}
\right)
\label{eq:ideal_orbit_matrix}
\end{equation}
%
Thus, the inverse relationship for the real orbit in terms of the ideal orbit for Step 1 can be obtained by using some matrix manipulations, and the result is as follows:
%
\begin{equation}
\begin{pmatrix}
u \\
v
\end{pmatrix} = \frac{1}{det \, \mathrm{\mathbf{Q}}}
\begin{pmatrix}
o_{33} - o_{23} v^{id}/R & -(o_{13} - o_{23} u^{id}/R \\
-(o_{31} - o_{21} v^{id}/R) & o_{11} - o_{21} u^{id}/R \\
\end{pmatrix}
\times 
\begin{pmatrix}
u^{id'} - d_x \\
v^{id'} - d_z
\end{pmatrix}
\label{eq:misaligned_orbit_matrix}
\end{equation}
%
where, 
%
\begin{equation}
\begin{pmatrix}
u^{id'} \\
v^{id'}
\end{pmatrix} = \frac{R'_y}{R}
\begin{pmatrix}
u^{id}\\
v^{id}
\end{pmatrix}
\end{equation}
%
and the determinant in Eq.~\ref{eq:misaligned_orbit_matrix} is given as,
%
\begin{equation}
\begin{aligned}
det \, \mathrm{\mathbf{Q}} \, = \, &(o_{11} - o_{21} u^{id}/R) (o_{33} - o_{23} v^{id}/R) \\
                           - &(o_{13} - o_{23} u^{id}/R) (o_{31} - o_{21} v^{id}/R ).
\end{aligned}
\label{eq:detQ}
\end{equation}

In Step 2, we need to parameterize the point marker's projection orbit on the misaligned detector using the Fourier coefficients.  We can write the discrete real Fourier series as follows, 
%
\begin{equation}\label{eq:fourierseries}
u_n = \frac{U_0}{2} + \sum ^{N/2-1}_{k=1} (U_k \cos (k\alpha_n)) + \tilde{U}_k \sin (k \alpha_n) + (-1)^{(n-1)} \frac{U_{N/2}}{2}, 
\end{equation}
%
with similar expressions for $v_n$.  The real Fourier coefficients are given by:
%
\begin{equation}\label{eq:fouriercoeff}
\begin{split}
U_k = & \frac{2}{N}\sum_{n=1}^{N} u_n \cos (k \alpha_n), \hspace{0.3cm} k = 0, ...., N/2, \\
\tilde{U}_k = & \frac{2}{N} \sum_{n=1}^{N} u_n \sin (k \alpha_n), \hspace{0.3cm} k = 1,...,N/2-1
\end{split}
\end{equation}
%
and analogously for $V_k$ and $\tilde{V_k}$.  Only the first three Fourier components were needed in the misalignment calculation.  Thus, the method is insensitive to high frequency fluctuations and uncertainties that stem from marker-point extraction between different projection angles.  These Fourier coefficients and the results from Step 1 are used to calculate the final system parameters by going through some intermediate equations.  These equations are shown in Appendix X.

The result of Smekal's method calculates ten parameters.  These are the detector rotation misalignment, $\theta_x$,$\theta_y$,$\theta_z$, detector position misalignment, $d_x$,$d_z$, $R$, and $R_y'$, where $R_y' = R + d_y$.  This method also provides the object marker initial location with respect to $R_f$, i.e., $x_0/R_f$, $y_0/R_f$, $z_0/R_f$.  Unfortunately, $R_f$ and marker initial locations are presented together and can no longer be separated using Smekal's calibration method.

%\begin{figure}
%\centering
%	\begin{subfigure}[b]{0.4\linewidth}
%	\centering
%	\placeholderimage[width=3cm,height=2cm]{FourierFit.png}
%	\label{fig:FourierFit}
%	\caption{Fourier coefficient fit to data}
%	\end{subfigure}
%\hspace{0.2cm}
%	\begin{subfigure}[b]{0.4\linewidth}
%	\centering
%	\placeholderimage[width=3cm,height=2cm]{smekalresult.png}
%	\label{fig:smekalresult}
%	\caption{Calculated result}
%	\end{subfigure}
%\label{fig:smekal_method}	
%\caption{Fitting result}
%\end{figure}

\subsection{Calculating the nuisance parameters and $R_{f}$}
In order to calculate $R_f$, we have opted to use an iterative search method.  Numerous search algorithms can be used to look for a parameter vector that resides in a multi-dimensional space.  We have opted to use the contracting-grid algorithm that allows the identification of a function's minimum in a fixed number of iterations using a fixed grid size~\citep{Hesterman2010}.  Along this search process for $R_f$, the values for six nuisance parameters were also calculated.

The contracting grid algorithm is based on maximum-likelihood estimation.  The maximum-likelihood method can generally be formulated as a search over parameter space using~\citep{Barrett2004},
%
\begin{equation}
\label{eq:mlem2}
\mathrm{\boldsymbol{\hat{\theta}}} = \arg\max_{\mathbf{\theta}} \; \mathrm{\lambda (\boldsymbol{\theta} | \mathbf{g})} = \arg\max_{\theta} \; \mathrm{pr( \mathbf{g}|\boldsymbol{\theta})},
\end{equation}
%
where $\boldsymbol{\theta}$ is a vector composed of parameters of interest, $\mathbf{g}$ is the data vector, $\lambda$ is the likelihood of observing $\mathbf{g}$, and $\boldsymbol{\hat{\theta}}$ is a vector of estimated parameters.  The data vector $\mathrm{\mathbf{g}}$ is composed of the pixel values in the image for all projection angles.  If the noise in the detector pixels are independent and identically distributed, where each pixel can be modeled using a zero-mean Gaussian function, then Eq.~\ref{eq:mlem2} is reduced to
%
\begin{equation}
\arg\min_{\theta} \| \mathbf{g} - \mathbf{\bar{g}}(\boldsymbol{\theta}) \|^2,
\label{eq:least_square}
\end{equation}
%
where $\mathbf{\bar{g}}(\boldsymbol{\theta})$ is the mean of the image data vector without noise.  So the maximum-likelihood solution to Eq.~\ref{eq:mlem2} is to search over $\boldsymbol{\theta}$ in order to minimize the least-squares difference between $\mathrm{\mathbf{g}}$ and $\mathrm{\mathbf{\bar{g}}}$.  The image data vector without noise is calculated using the imaging equation,
%
\begin{equation}
\mathrm{\mathbf{ \bar{g}(\boldsymbol{\theta} ) } } = \mathrm{\mathbf{H}( \boldsymbol{\theta} )} \mathrm{\mathbf{\bar{f}} \boldsymbol{(\theta) }},
\end{equation}
%
where $\mathrm{\mathbf{H}}$ is the imaging system matrix.  This means $\mathrm{\mathbf{H}}$, $\mathrm{\mathbf{\bar{f}}}$, and $\mathrm{\mathbf{\bar{g}}}$ must be re-calculated each time a new $\boldsymbol{\theta}$ is used in the search algorithm.  

Unfortunately this method is not viable due to computation constraints.  For example, the projection of an phantom object was calculated in simulation with $64^3$ voxels over 360 degrees at 2-degree increment, where each projection image was $1024^2$ pixels.  This computation took over 30 seconds in CUDA.  Even if only 2 grids were used per parameter value, this means each contracting-grid iteration would require the same calculation to be repeated 128 times, totaling over an hour per iteration.  In an actual experiment where the the number of object voxels and parameter grids are required to be much larger, the calibration step would take too long to be realistic.  Instead, we have decided to replace $\mathrm{\mathbf{\bar{f}}}( \boldsymbol{\theta})$ by a set of coordinate locations for each fiducial markers in the global coordinate system ($\bar{x_i}$, $\bar{y_i}$, $\bar{z_i}$).  The imaging matrix, $\mathrm{\mathbf{H}}$, can be replaced by first applying a rotation and translation matrix onto each marker's position to incorporate the position and orientation misalignment of the object, then use Eq.~\ref{eq:uid_vid}-\ref{eq:detQ} to obtain $\bar{u}_i$ and $\bar{v}_i$, which are the projection positions of the markers on the misaligned detector.  These are used in place of $\mathrm{\mathbf{\bar{g}}}( \boldsymbol{\theta})$.  The image data, $\mathrm{\mathbf{g}}$ is replaced by the coordinates of the fiducial markers obtained from image data, $(\hat{u}_i, \hat{v}_i)$, which are acquired via centroid estimation using,
%
\begin{equation}
\hat{u}_i = \frac{\sum\limits_{n = 1}^{N} g_{in} u_{in}}{\sum\limits_{n = 1}^{N_i} g_{in}}, \qquad
\hat{v}_i = \frac{\sum\limits_{n = 1}^{N} g_{in} v_{in}}{\sum\limits_{n = 1}^{N_i} g_{in}},
\end{equation}
\label{eq:centroid_estimation}
%
where $g_{in}$ is the pixel value at location $u_{in}$ for the $i^{th}$ fiducial marker.  The contracting-grid algorithm was applied to search over $\boldsymbol{\theta}$ by minimizing the least-squares difference, $d$, between $\bar{u}_i$, $\bar{v}_i$ and $u_i$, $v_i$ using
%
\begin{equation}
d = \sum\limits_i \sqrt{ ( \bar{u_i} - \hat{u}_i )^2 + ( \bar{v_i} - \hat{v}_i)^2 }.
\end{equation}
%
We note that by reducing data size and performing centroid estimation, the noise models on $\hat{u}_i$ and $\hat{v}_i$ are no longer zero-mean Gaussian functions.

The parameter grid used in the algorithm is a discrete set of numbers each centered about the parameter value.  The initial spacing within each parameter grid is $\Delta \theta^0 = D_i/(N-1)$, where $D_i$ is the grid size and $N$ is the number of grid points used for each parameter, which we have kept as a constant value.  Since we can physically measure each parameter in the beginning, at least within a few millimeters or degrees, the grids are centered about these initial values.  We have set the grid size, $D_i$ for distance measurements to be $\pm 5$ mm and orientation measurements to be $\pm 3 \degree$.  We have chosen to set the number of grid points, $N$, to be 4 in order to limit the amount of time used in each iteration.  In the subsequent iterations, the grid size for the $k^{th}$ iteration contracts to a smaller size using
%
\begin{equation}
\label{eq:parameter_spacing}
\Delta \theta^k = \frac{\Delta \theta^{k-1}}{\gamma},
\end{equation}
%
where $\gamma$ is the contracting rate, and a new set of parameters are chosen as the new grid centers.  The contracting-grid algorithm can broken down into five steps:
%
\begin{enumerate}
\item For each parameter $\theta_i$, create a region of physically reasonable grid size.
\item Use Eq.~\ref{eq:least_square} and calculate the least-squared results of all parameter grid combinations.
\item Find the set of parameters that generated the lowest least-squared result.  This is the starting point for the next iteration.
\item Contract the grid size for centered about the parameters from the previous step using Eq.~\ref{eq:parameter_spacing}.
\item Repeat Steps 2-4 until the algorithm reaches a preset number of iterations.
\end{enumerate}
%\comment{ Include parameter grid sizes as a table?} 
Detailed information regarding the contracting-grid search algorithm is given in the paper by Jacob Y. Hesterman~\citep{Hesterman2010}.  

Through experimentation, we have found that it is more efficient to first obtain a rough estimate of the parameters, $R_f$, $\theta^{obj}_z$, $\theta^{obj}_x$, and $\theta^{obj}_y$ before using the contracting-grid algorithm.  A rough estimation of $R_f$ can simply be found by using the vertical separation between the point markers on the projection image ($\Delta z_0$) of a known phantom and applying it to the values $\Delta z_0/R_f$ calculated from the previous section.  $\theta^{obj}_x$ is the initial rotation orientation of the point markers about the z-axis, changing this value does not affect the overall projection locations of the point markers but it does greatly contribute to the least-squares sum of the contracting-grid algorithm.  Therefore, we have approximated its value in order to minimize the search duration later.  Finally, the values for $\theta_x^{obj}$ and $\theta_y^{obj}$ are iterated over 360$\degree$ to obtain the initial parameters.

\subsection{Calibration results}
\label{subsect:cali_results}
Figure~\ref{fig:calibration_plot} shows the projections of the ball bearings from experiment vs. the projections of point markers using the calibration parameters.  We have tested various number of grid points ranging from 2 to 10 and contracting rate between 1.05 to 1.3.  Larger grid size requires more time to compute while slower contracting rate takes longer to converge.  Through experimentation, we have settled to use 100 contracting-grid iterations with a 4 grid points for each parameter at a contracting rate of 1.05.
%
\begin{figure}[h]
\includegraphics[scale=0.7]{calibration_plot.eps}
\caption{Projection of the ball bearings from experiment vs. the projection of the point markers using the calibration parameters after 100 iterations with a grid size of 4 and a contracting rate of 1.05.}
\label{fig:calibration_plot}
\end{figure}

Table~\ref{table:calibration_result} shows the calibration results of the CT system.  Note that $R_f$ is calculated using the contracting-grid algorithm without using a noise model.  We have obtained the standard deviation on $R_f$ by plotting the mean-squared error between experimental and calibration result for various $R_f$ values centered at the $R_f$ found via calibration.  Shown in Fig.~\ref{fig:Rf_deviation}, we can see that $R_f$ can deviate $\pm$1 mm to still remain within \%0.5 of the mean-squared error obtained with calibration.
%
\begin{figure}
	\includegraphics[scale=0.7]{Rf_deviation.eps}
	\caption{The deviation of $R_f$ against the mean-squared error obtained using results obtained from calibration.}
	\label{fig:Rf_deviation}
\end{figure}
%

The most important angular measurement is $\theta_y$ because it accounts for the image rotation about the optical axis.  Errors in this parameter can result in severe artifacts in the reconstruction image.  Both $\theta_x$ and $\theta_z$ are less important; in fact, these values were assumed to be zero in some calibration methods~\citep{Noo2000, Cho2005, Yang2006}.  
%
\begin{center}
	\begin{table}[ht]\caption{Calibration Results}
		\begin{tabular}{c | c | r}
		\hline
		Parameter &	Value & Standard Deviation \\ \hline \hline
		$R$ & 1106.3 (mm) & 2.43 (mm)\\ \hline
		$R_f$ & 900.7 (mm)&  1 (mm) \\ \hline
		$d_x$ & 4.01 (mm)& 0.0028 (mm)\\ \hline
		$d_z$ & -1.40 (mm)& 0.10 (mm)\\ \hline
		$\theta_x$ & -0.019 (radians)& 1.0743 (radians)\\ \hline
		$\theta_y$ & 0.0039 (radians)& 0.0003 (radians)\\ \hline
		$\theta_z$ & -0.0047 (radians)& 0.0089 (radians)\\ \hline	
		$M$ & 13.1 & 0.24 \\ \hline
		\end{tabular}
	\end{table}
	\label{table:calibration_result}
\end{center}

\section{Calibration Phantom}
The phantom used in the calibration process was designed in SolidWorks and printed using the rapid prototype machine at the Center for Gamma-Ray Imaging (CGRI).  The phantom is composed of two separate pieces: a large bracket that is mounted on the rotation stage and a smaller insert where a number of ball bearings and sizes can be attached.  The bracket and multiple inserts are shown in Fig.~\ref{fig:calibration_phantom}.

The bracket is designed so that the center of the ball bearings on the inserts is 60 mm from the center of the rotation axis on the bracket.  The smaller insert has a conical end so it is easy to align the vertical axis of the markers against the bracket holder.  The ball bearings are made out of stainless steel and are purchased from McMaster-Carr.  Three different bearing sizes (1/16\inches, 1/8\inches,~ 3/16\inches ~and 1/4\inches) were purchased and tested.  Through experiments we have found that the 1/8\inches~ ball bearings worked the best.
%
\begin{figure}[ht]
	\begin{subfigure}[b]{0.3\linewidth}
	\includegraphics[width = 4cm]{phantom_bracket_clip.png}
	\label{fig:calibration_phantom_bracket}
	\caption{}
	\end{subfigure}
\hspace{0.2cm}
	\begin{subfigure}[b]{0.3\linewidth}
	\includegraphics[width = 4cm]{phantom_insert2_crop.png}
	\label{fig:calibration_phantom_insert}
	\caption{}
	\end{subfigure}
\caption{(a) Calibration phantom bracket, and (b) inserts with different ball bearings.}
\label{fig:calibration_phantom}
\end{figure}

\subsection{Extract phantom marker locations}
In order to use the calibration method described in Section~\ref{section:calibration_method}, we must be able to extract the 2-dimensional coordinate location of the point markers on the detector using the phantom ball bearing projection images.  The raw projection image at one angle is shown in Fig.~\ref{fig:calibration_projection}.
%
\begin{figure}[ht]
\centering
\includegraphics[width = 10cm]{calibration_projection_w_label}
\caption{Projection of the calibration phantom at one angle.  The image taken used 100 kV x-ray at 200 $\mu A$ with a 2 second exposure time.}
\label{fig:calibration_projection}
\end{figure}

Upon close inspection, although we can see the ball bearings clearly, the image is littered with small clusters of high-value pixels, also shown in Fig.~\ref{fig:calibration_projection}.  These clusters of bright pixels are the result of direct x-ray interactions, where the x-ray energies are deposited inside the detector, resulting in high detector values.  They cannot be completely eliminated even after we carefully shield the camera with lead plates.  The locations of these clusters are random and vary from image to image; typically higher x-ray tube energies (>60 kVp) produce more clusters than lower x-ray tube energies.  However, we wish to calibrate using higher x-ray tube energies because while the projection of the steel ball bearings will remain dark, the projection of the plastic phantom material will be lighter.  The higher contrast difference between the two materials allows us to extract the ball bearing location more easily without having to repeat the same experiment again, without the ball-bearings.  Fortunately, we can eliminate the majority of these high-value clusters by thresholding the entire image.  The result is an intermediate image with the majority of phantom structures removed, as well as the majority of these high-value clusters, leaving only the clusters of ball bearing projections and other smaller clusters left over from the phantom structures.  Unfortunately, at this stage, we cannot simply use well-known clustering algorithms such as \textit{k-mean} to extract the centroid locations.  This is because the algorithm require us to fix the number of clusters in the image.  While we know the number of ball bearing clusters we need to identify, we do not know the number of smaller clusters left over after thresholding since it varies in every image.  Instead, we use a slightly more tedious method to search for each ball bearing projection cluster.  This method can be summarized by the following steps:
%
\begin{enumerate}
\item \label{sort:1} Sort all points in the main image array by their y-coordinate.
\item \label{sort:2} Retrieve the first point's x and y coordinate and set it as the center of the cluster.
\item \label{sort:3} Find the next point that is closest to the first point.
\item \label{sort:4} Re-calculate the center cluster coordinate using the neighboring point by averaging the x and y coordinate of the points.
\item \label{sort:5} Iterate through all points and repeat Step~\ref{sort:3}-\ref{sort:4} until all points that are close to each other have been approximately identified and calculate a mean cluster coordinate using these identified points.
\item \label{sort:6} Recalculate the center coordinate for the cluster using all of the points identified in Step~\ref{sort:5}, then iterate through all points again in the main image array to ensure that no points for this cluster were missed.
\item \label{sort:8} Reject this cluster if it is too small in terms of size or the number of points.
\item \label{sort:9} Record the cluster center coordinate and remove all points from this cluster from the main image array.
\item \label{sort:10} Repeat Step~\ref{sort:2}-\ref{sort:9} until the image cluster size reaches zero.
\end{enumerate}

The cluster center is simply the mean of the x-coordinate and y-coordinate of the cluster points.  The main idea for this method is to assume that points close to each other belong in the same cluster.  This is the reasoning behind Step \ref{sort:1}, where we needed to first sort all points by their coordinate position.  We reason that, after all points are sorted, then if we iteratively go through all points in the main array, all points that are within a cluster should be very close to each other.  We use the mean cluster point as a reference to determine whether the next point should be included in the current cluster.  The criterion for this determination is distance.  If the distance between the current cluster center and the next point is close, then we classify the next point as a cluster point and repeat until we have searched iteratively through all points in the image array, Step~\ref{sort:2}-\ref{sort:6}.  The distance used in this method is the approximate image size of the ball bearing measured visually using one calibration image.  Once a cluster is identified, we look through all of the points in the array once more to ensure that no points that should have been included in this cluster were not over looked(Step~\ref{sort:6}).  Once this cluster is identified, we classify this cluster as either a ball bearing projection cluster, or a background noise cluster based on how many points are in this cluster and the cluster physical size (step~\ref{sort:8}).  The limit on the number of points and size limit were approximated using one calibration image by visual inspection.  A secondary array maps the points in the image array to the newly identified cluster; thus, these points are not used when the algorithm repeats Step~\ref{sort:2}-\ref{sort:9} in search for a new cluster.  Since this method iterates through the main image array twice for each cluster, outwardly it can be a very slow method.  However, since we remove all points in the cluster each time a cluster is identified, the method speeds up as more clusters are found.  In fact, once the raw projection image is thresholded (before using this method), we are left with only approximately 10,000 - 30,000 points, which is very manageable size using MATLAB.  In the end, this method only takes about 1-2 seconds to identify and calculate the centroid coordinates in each raw calibration image.  The calibration code can be downloaded from the git public repository: \hyperref[]{\url{https://bitbucket.org/hxfan/matlab_calc}}.

Figure~\ref{fig:clustering_algorithm} provides a graphical description of the clustering algorithm described in this section.  In this figure, each point represents a point from the projection image after thresholding.  The number above each point represents its rank order after the points are sorted by the coordinate position (y coordinate).  The cluster center point is used as a reference to find the next cluster point, and it is recalculated after the next cluster point is identified.  Shown in the figure, once the 6\textsuperscript{th} cluster point is identified, the distance between the center-of-mass point and point 7 exceeds $R_{point \; cluster}$; therefore, points 7 and 8 do not belong to cluster 1 and will not be used to calculate the next cluster center point.  Also shown is the cluster center point after point 24 is identified. The distance $d_3$ between the cluster point point and point 25 exceeds $R_{point \; cluster}$ therefore point 25 is also ruled out and does not belong to cluster 1.  Cluster 2 includes points 7, 8, 13, and 14; however, because this cluster is too small so it is classified as noise cluster.  Point 25 is also ruled out as belonging to any cluster.  Clusters 1 and 3 are classified as ball bearing projection clusters with corresponding centroid positions.
%
\begin{figure}[ht]
\centering
\includegraphics[scale=1.2]{clustering_algorithm}
\caption{A graphical description of the clustering algorithm.  }
\label{fig:clustering_algorithm}
\end{figure}

%Here, the number above each point indicates its rank order after the points are sorted according to the sort direction.  $R_{point \; cluster}$ is a predetermined distance after looking through the raw calibration image.  The center-of-mass point is recalculated after each cluster point is identified.  After the center-of-mass point is recalculated once point 6 is identified, the distance $d_1$ is much greater than $R_{point \; cluster}$; therefore, points 7 and 8 are ruled out from cluster 1, as well as point 13 and 14.  Point 25 is also ruled out because $d_3$ is much greater than the $R_{point \; cluster}$ after the center-of-mass point is recalculated once point 24 is identified.  Cluster 2 is classified as noise cluster because it does not have enough points within the cluster.  Cluster 3 is identified as a ball bearing projection cluster because of its size and the number of points within the cluster.

%\comment{ Should I provide an example using real calibration image? }

\section{Summary}
In this chapter, we have described the calibration method for the prototype CT system.  We began by providing an overview of some of the existing methods for calibrating bench-top x-ray CT systems.  Then, we followed by defining the geometry of the system and describing the steps that were taken to extrapolate all 14 parameters of the system.  The final results of the system parameters are shown in Section~\ref{subsect:cali_results}.  The last two sections of this chapter describes the physical calibration phantom and the algorithm that were used to extract the ball bearing projection points from raw calibration images.  


%\section{Calculating the nuisance parameters and $R_f$}
%In order to calculate $R_f$, we have opted to use an iterative search method.  There are numerous search algorithms that can be used to search a parameter vector that resides in a multi-dimensional space.  We have opted to use the contracting-grid algorithm that allows identification of a function's minimum in a fixed number of iterations using a fixed grid size~\citep{Hesterman2010}.  Along this search process for $R_f$, we must also calculate the values for six nuisance parameters.
%
%The contracting grid algorithm is based on maximum-likelihood estimation.  The maximum-likelihood method can generally be formulated as a search over parameter space using~\citep{Barrett2004},
%%
%\begin{equation}
%\label{eq:mlem2}
%\mathrm{\boldsymbol{\hat{\theta}}} = \arg\max_{\mathbf{\theta}} \; \mathrm{\lambda (\boldsymbol{\theta} | \mathbf{g})} = \arg\max_{\theta} \; \mathrm{pr( \mathbf{g}|\boldsymbol{\theta})},
%\end{equation}
%%
%where $\boldsymbol{\theta}$ is a vector composed of parameters of interest, $\mathbf{g}$ is the data vector, $\lambda$ is the likelihood of observing $\mathbf{g}$, and $\boldsymbol{\hat{\theta}}$ is a vector of estimated parameters.  The data vector $\mathrm{\mathbf{g}}$ is composed of the pixel values in the image.  If we model the noise in each pixel using a zero-mean Gaussian function, and assume the pixels are independent and identically distributed in the detector, then the maximum-likelihood solution to Eq.~\ref{eq:mlem2} is then reduced a search over the parameter space, $\mathrm{\mathbf{\theta}}$, in order to minimize the least-squares difference between $\mathrm{\mathbf{g}}$ and $\mathrm{\mathbf{\bar{g}}}$ using
%%
%\begin{equation}
%\arg\min_{\theta} \| \mathbf{g} - \mathbf{\bar{g}}(\mathbf{\theta}) \|^2.
%\label{eq:least_square}
%\end{equation}
%%
%where $\mathbf{\bar{g}}(\mathbf{\theta})$ is the mean of the image data vector without noise, calculated using the imaging equation,
%%
%\begin{equation}
%\mathrm{\mathbf{ \bar{g}(\theta) } } = \mathrm{\mathbf{H}( \boldsymbol{\theta} )} \mathrm{\mathbf{\bar{f}} \boldsymbol{(\theta) }},
%\end{equation}
%%
%where $\mathrm{\mathbf{H}}$ is the imaging system matrix.  This means $\mathrm{\mathbf{H}}$, $\mathrm{\mathbf{\bar{f}}}$, and $\mathrm{\mathbf{\bar{g}}}$ must be recalculated each time a new $\boldsymbol{\theta}$ is used in the search algorithm.  Unfortunately this method is not viable due to computation constraints.  For example, if we calculate projection of an object with $64 \times64 \times 64$ voxels over 360 angles at 1 degree increment, and the image size at each projection angle is $512 \times 512$, then $\mathrm{\mathbf{H}}$ is $ 94371840 \times 262144$.  This and $\mathrm{\mathbf{\bar{f}}( \boldsymbol{\theta})}$ must be recalculated for each $\boldsymbol{\theta}$.  We have implemented this method in the contracting-grid search in CUDA on a much smaller scale using $64 \times 64 \times 64$ voxels with $256 \times 256$ projection image over 180 angles.  We have found that it was extremely time consuming to iterate and search over $\boldsymbol{\theta}$ using this method, especially when our detectors have a much larger array size.  Instead, we have decided to reduce $\mathrm{\mathbf{\bar{f}}}$ into a set of positions for each fiducial markers in the global coordinate system ($\bar{x_i}$, $\bar{y_i}$, $\bar{z_i}$), and $\mathrm{\mathbf{\bar{g}}}$ into a set of projected position for each fiducial markers on the misaligned detector ($\bar{u}_i, \bar{v}_i$), where $i$ is the number of fiducial markers.  Equation~\ref{eq:uid_vid}-~\ref{eq:detQ} are used to map from global coordinate ($x_i$, $y_i$, $z_i$) to the local coordinate on the detector ($u_i, v_i$).  The coordinates of the fiducial markers estimated from image data, $(x_i, y_i, z_i)$, and are acquired via centroid estimation using,
%%
%\begin{equation}
%u_i = \frac{\sum\limits_{n = 1}^{N} g_{in} u_{in}}{\sum\limits_{n = 1}^{N_i} g_{in}}, \qquad
%v_i = \frac{\sum\limits_{n = 1}^{N} g_{in} v_{in}}{\sum\limits_{n = 1}^{N_i} g_{in}},
%\end{equation}
%%
%where $g_{in}$ is the pixel value at location $u_{in}$ for the $i^{th}$ fiducial marker.  To search over parameter space, we will try to minimize the least-squares difference, $d$, between $\bar{u}_i$, $\bar{v}_i$ and $u_i$, $v_i$ using
%%
%\begin{equation}
%d = \sqrt{ ( \bar{u_i} - u_i )^2 + ( \bar{v_i} - v_i)^2 }.
%\end{equation}
%%
%We realize that by reducing data size and performing centroid estimation, the noise model on $u_i$ and $v_i$ are no longer Gaussian.
%
%Plot the mean-squared error between the estimated bb locations using our projection model and the bb locations extracted from experimental images for various $R_f$ positions, shown in Fig. X, when $R_f$ estimation is within X-mm, MSE is reasonably low.  So we call that good enough.
%
%
%
%
%
%
%
%
%
%
%
%
%












%old part of the beginning of contracting-grid and MLEM 
%In order to calculate $R_{f}$, we have opted to use an iterative search method.  There are numerous search algorithms that can be used to search a parameter vector that resides in a multi-dimensional space.  We have opted to use the contracting-grid algorithm that allows identification of a function's minimum in a fixed number of iterations using a fixed grid size.  Along this search process for $R_f$, we must also calculate the values for six nuisance parameters.  
%
%The contracting grid algorithm is based on maximum-likelihood estimation.  The maximum-likelihood method can generally be formulated as a search over parameter space as,
%%
%\begin{equation}
%\label{eq:mlem}
%\mathrm{\boldsymbol{\hat{\theta}}} = \arg\max_{\mathbf{\theta}} \; \mathrm{\lambda (\boldsymbol{\theta} | \mathbf{g})} = \arg\max_{\theta} \; \mathrm{pr( \mathbf{g}|\boldsymbol{\theta})},
%\end{equation}
%%
%where $\boldsymbol{\theta}$ is a vector composed of parameters of interest, $\mathbf{g}$ is the data vector, $\lambda$ is the likelihood of observing $\mathbf{g}$, and $\boldsymbol{\hat{\theta}}$ is a vector of estimated parameters.  The data vector, $\mathbf{g}$, in our problem are the coordinates of the phantom marker projection points on the misaligned detector. The parameter vector $\boldsymbol{\theta}$ is composed of the targeted system parameter, $R_f$, and the nuisance parameters ($\theta_x^{obj}, \theta_y^{obj}, \theta_z^{obj}, x_0, y_0, z_0$).  We have also assumed that the probability model, $\mathrm{pr( \mathbf{g}|\boldsymbol{\theta})}$, is a multivariate Gaussian function with a diagonal covariance matrix.  The variances in the diagonal matrix represent how well we can estimate the phantom marker projection coordinates on the misaligned detector.  Assuming that our ability to estimate these coordinates are the same for each marker, the variances in the covariance matrix are identical.  Using our assumptions, the maximum-likelihood solution is then reduced to solve
%%
%\begin{equation}
%\arg\min_{\theta} \| \mathbf{g} - \mathbf{\bar{g}}(\mathbf{\theta}) \|^2,
%\label{eq:least_square}
%\end{equation}
%%
%which is equivalent to the least-squares solution.  In other words, find the parameter vector $\boldsymbol{\theta}$ that minimizes the mean-squared difference between the observed data, $\mathbf{g}$, and the parameter-dependent mean, $\mathbf{\bar{g}}\mathbf{(\theta)}$, calculated using Eq.~\ref{eq:rotation_matrix}~-~\ref{eq:detQ}.






%
%\begin{equation}\label{eq:d_coeff}
%\begin{split}
%d_{22}' =& \; (U_3^2 - U_1^2 + \tilde{U}_3^2 - \tilde{U}_1^2)/2 \\
%d_{20}' =& \; ((U_1 - U_3)\,U_2 - (\tilde{U}_3 - \tilde{U}_1)\tilde{U}_2)/d_{22}' \\
%d_{21}' =& \; ((U_1 + U_3)\tilde{U}_2 - (\tilde{U}_3 + \tilde{U}_1) U_2)/ d_{22}' \\
%d_{00}' =& \; ((U_0 + U_2)\,d_{20}' + \tilde{U}_2 \, d_{21}' + 2 U_1)/2 \\
%d_{01}' =& \; (\tilde{U}_2 \, d_{20}' + (U_0 - U_2)\, d_{21}' + 2 \tilde{U}_1)/2  \\
%d_{02}' =& \; (U_1 d_{20}' + \tilde{U}_1 \, d_{21}' + U_0)/2 \\
%d_{10}' =& \; ( (V_0 + V_2) \, d_{20}' + \tilde{V}_2 \, d_{21}' + 2 V_1 )/2 \\
%d_{11}' =& \; (\tilde{V}_2 d_{20}' + \tilde{V}_2 \, d_{21}' + 2 V_1)/2 \\
%d_{12}' =& \; (V_1 \, d_{20}' + \tilde{V}_1 \, d_{21}' + V_0)/2   \\
%\end{split}
%\end{equation}
%
%\begin{equation}\label{eq:c_coeff}
%\begin{split}
%&
%\begin{pmatrix}
%c_{00}' \\
%c_{01}' 
%\end{pmatrix} = \frac{1}{d_{20}'^2 + d_{21}'^2}
%\begin{pmatrix}
%d_{20}' & d_{21}' \\
%d_{21}' & d_{20}'
%\end{pmatrix}
%\left[ \frac{1}{2}
%\begin{pmatrix}
%U_2 & \tilde{U}_2 \\
%\tilde{U}_2 & -U_2
%\end{pmatrix}
%\begin{pmatrix}
%d_{20}' \\ d_{21}'
%\end{pmatrix}
%+ \begin{pmatrix}
%U_1 \\ \tilde{U_1}
%\end{pmatrix}
%\right]
%+ \begin{pmatrix}
%U_2/2 \\ 0
%\end{pmatrix} \\
%&
%\begin{pmatrix}
%c_{10}' \\ c_{11}'
%\end{pmatrix} 
%= \frac{1}{d_{20}' + d_{21}'^2}
%\begin{pmatrix}
%d_{20}' & d_{21}' \\
%d_{21}' & d_{20}'
%\end{pmatrix}
%\left[ \frac{1}{2}
%\begin{pmatrix}
%V_2 & \tilde{V}_2 \\
%\tilde{V}_2 & -V_2
%\end{pmatrix}
%\begin{pmatrix}
%d_{20}' \\ d_{21}'
%\end{pmatrix}
%+ \begin{pmatrix}
%V_1 \\ \tilde{V_1}
%\end{pmatrix}
%\right]
%+ \begin{pmatrix}
%V_2/2 \\ 0
%\end{pmatrix}
%\end{split}
%\end{equation}
%
%\begin{equation}
%\label{eq:eta}
%\tan \eta = - \frac{c_{11}'}{c_{01}'}
%\end{equation}
%
%\begin{equation}
%\label{eq:ABCEF}
%\begin{split}
%A =& \sin \eta \; c_{00}' + \cos \eta \; c_{10}' \\
%B =& \cos \eta \; c_{01}' + \sin \eta \; c_{11}' \\
%C =& \cos \eta \; c_{00}' - \sin \eta \; c_{10}' \\
%E =& \sin \eta \; d_{02}' + \cos \eta \; d_{12}' \\
%F =& \cos \eta \; d_{02}' + \sin \eta \; d_{12}' \\
%\end{split}
%\end{equation}
%
%\begin{equation}
%\label{eq:theta}
%\sin \theta = \frac{B (F_k - F_j)}{(E_k - E_j)(C - F_k)-(F_k - F_j)(A - E_k)}
%\end{equation}
%
%\begin{equation}
%\label{eq:varphi}
%\tan \varphi = \frac{C-F}{\sin \theta \, (A-E) \, \pm \, B}
%\end{equation}